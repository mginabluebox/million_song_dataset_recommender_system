{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "voluntary-russian",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import dask\n",
    "import dask.bag as db\n",
    "import dask.dataframe as dd\n",
    "from distributed import Client\n",
    "from dask_jobqueue import SLURMCluster\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "electric-brighton",
   "metadata": {},
   "outputs": [],
   "source": [
    "public_path = '/scratch/work/public/MillionSongDataset/AdditionalFiles/'\n",
    "local_path = '/scratch/tj810/final-project-team_unsupervised_learners/feature_files/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "environmental-offer",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ext3/miniconda3/lib/python3.8/site-packages/distributed/node.py:151: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 42963 instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51511590a4544d85a7778a6ec531844b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>SLURMCluster</h2>'), HBox(children=(HTML(value='\\n<div>\\n  <style scoped>\\n    …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://10.32.35.15:43565</li>\n",
       "  <li><b>Dashboard: </b><a href='http://10.32.35.15:42963/status' target='_blank'>http://10.32.35.15:42963/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>0</li>\n",
       "  <li><b>Cores: </b>0</li>\n",
       "  <li><b>Memory: </b>0 B</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://10.32.35.15:43565' processes=0 threads=0, memory=0 B>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set LOCAL to True for single-machine execution while developing\n",
    "# Set LOCAL to False for cluster execution\n",
    "LOCAL = False\n",
    "\n",
    "if LOCAL:\n",
    "    # This line creates a single-machine dask client\n",
    "    client = Client()\n",
    "else:    \n",
    "    # This line creates a SLURM cluster dask and dask client\n",
    "    # Logging outputs will be stored in /scratch/{your-netid}\n",
    "    \n",
    "    cluster = SLURMCluster(memory='4GB', cores=2, python='/scratch/work/public/dask/bin/python', \n",
    "                               local_directory='/tmp/{}/'.format(os.environ['SLURM_JOB_USER']),\n",
    "                               job_extra=['--output=/scratch/{}/slurm-%j.out'.format(os.environ['SLURM_JOB_USER'])])\n",
    "\n",
    "    cluster.submit_command = 'slurm'\n",
    "    cluster.scale(100)\n",
    "\n",
    "    display(cluster)\n",
    "    client = Client(cluster)\n",
    "\n",
    "display(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "short-aircraft",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BROKEN_lastfm_tags.db',\n",
       " 'README',\n",
       " 'lastfm_tags.db',\n",
       " 'LICENSE',\n",
       " 'unique_terms.txt',\n",
       " 'artist_term.db',\n",
       " 'artist_location.txt',\n",
       " 'artist_similarity.db',\n",
       " 'mxm_779k_matches.txt',\n",
       " 'sid_mismatches.csv',\n",
       " 'rdio_ids.txt',\n",
       " 'sid_mismatches.txt',\n",
       " 'TRACKIDS.txt',\n",
       " 'msd_summary_file.h5',\n",
       " 'unique_tracks.txt',\n",
       " 'mxm_dataset.db',\n",
       " 'unique_mbtags.txt',\n",
       " 'unique_artists.txt',\n",
       " 'tracks_per_year.txt',\n",
       " 'track_metadata.db']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(public_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "modern-wrong",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conn = sqlite3.connect(path + '.db')\n",
    "# cur = conn.cursor()\n",
    "# cur.execute(\"SELECT * FROM artist_term LIMIT 1\")\n",
    "# cur.execute(\"\"\"SELECT sql FROM sqlite_master WHERE type='table'\"\"\")\n",
    "# print(cur.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "temporal-harvest",
   "metadata": {},
   "source": [
    "# Save tables to local folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fatal-brook",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(public_path + 'track_metadata.db')\n",
    "df = pd.read_sql_query(\"SELECT * from songs\", conn).replace([None], np.nan) \n",
    "# df.to_csv('/scratch/tj810/final-project-team_unsupervised_learners/feature_files/track_metadata.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "acoustic-fifteen",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(public_path + 'artist_term.db')\n",
    "df = pd.read_sql_query(\"SELECT * from artist_term\", conn)\\\n",
    "        .replace([None], np.nan)\\\n",
    "        .groupby('artist_id')['term']\\ # combine all terms associated with each artist\n",
    "        .apply(list).reset_index()\n",
    "# df.to_csv('/scratch/tj810/final-project-team_unsupervised_learners/feature_files/artist_term.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reliable-handbook",
   "metadata": {},
   "source": [
    "# Combine all features from Additional_Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "stainless-albert",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ext3/miniconda3/lib/python3.8/site-packages/dask/dataframe/io/csv.py:538: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  head = reader(BytesIO(b_sample), **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# features: duration, artist_familiarity, artist_hotttnessss, year\n",
    "# includes track_id, artist_id\n",
    "track_metadata = dd.read_csv(local_path + 'track_metadata.csv', header = 0).repartition(100)\n",
    "\n",
    "# features: artist location (map using artist_id)\n",
    "artist_location = dd.read_csv(public_path+'artist_location.txt',\n",
    "                              sep= '<SEP>',\n",
    "                              header = None, \n",
    "                              names = ['artist_id','latitude','longtitude','artist_name','location'])\n",
    "\n",
    "# features: artist term (map using artist_id)\n",
    "artist_term = dd.read_csv(local_path + 'artist_term.csv', header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "regular-thousand",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['artist_id', 'term'], dtype='object')\n",
      "Index(['artist_id', 'latitude', 'longtitude', 'artist_name', 'location'], dtype='object')\n",
      "Index(['track_id', 'title', 'song_id', 'release', 'artist_id', 'artist_mbid',\n",
      "       'artist_name', 'duration', 'artist_familiarity', 'artist_hotttnesss',\n",
      "       'year'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(artist_term.columns) # (43943, 2)\n",
    "print(artist_location.columns) # 13850 rows × 5 columns\n",
    "print(track_metadata.columns) # (1000000, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "usual-amount",
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_features = artist_term.merge(artist_location, how='outer', on = 'artist_id').repartition(npartitions=1)\n",
    "all_features = track_metadata.merge(artist_features, how='left', on = 'artist_id').compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "accredited-recommendation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_features.drop(columns='artist_name_y').rename(columns={'artist_name_x':'artist_name'}).reset_index(drop=True).to_csv(local_path + 'all_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "palestinian-republican",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "track_id                                             TRMMMRX128F93187D9\n",
       "title                                                 No One Could Ever\n",
       "song_id                                              SOGTUKN12AB017F4F1\n",
       "release                                                          Butter\n",
       "artist_id                                            ARGEKB01187FB50750\n",
       "artist_mbid                        3d403d44-36ce-465c-ad43-ae877e65adc4\n",
       "artist_name                                              Hudson Mohawke\n",
       "duration                                                      138.97098\n",
       "artist_familiarity                                             0.643681\n",
       "artist_hotttnesss                                              0.437504\n",
       "year                                                               2006\n",
       "term                  ['broken beat', 'hip hop', 'trip hop', 'glitch...\n",
       "latitude                                                        55.8578\n",
       "longtitude                                                     -4.24251\n",
       "location                                              Glasgow, Scotland\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.loc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "recognized-nicaragua",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(features.shape[1]):\n",
    "#     print(f'Number of unique {features.columns[i]}:')\n",
    "#     print(features[features.columns[i]].unique().size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "likely-broadcast",
   "metadata": {},
   "source": [
    "# Get additional features from hdf5 files directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bored-tractor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PythonSrc.hdf5_getters as hdf5_getters\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "liked-eligibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "public_path = '/scratch/work/public/MillionSongDataset/'\n",
    "local_path = '/scratch/tj810/final-project-team_unsupervised_learners/feature_files/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "empty-content",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000001"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_all_files(basedir,ext='.h5') :\n",
    "    cnt = 0\n",
    "    for root, dirs, files in os.walk(basedir):\n",
    "        files = glob(os.path.join(root,'*'+ext))\n",
    "        cnt += len(files)\n",
    "    return cnt\n",
    "count_all_files(public_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "located-collective",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_num_songs\n",
      "get_artist_familiarity\n",
      "get_artist_hotttnesss\n",
      "get_artist_id\n",
      "get_artist_mbid\n",
      "get_artist_playmeid\n",
      "get_artist_7digitalid\n",
      "get_artist_latitude\n",
      "get_artist_longitude\n",
      "get_artist_location\n",
      "get_artist_name\n",
      "get_release\n",
      "get_release_7digitalid\n",
      "get_song_id\n",
      "get_song_hotttnesss\n",
      "get_title\n",
      "get_track_7digitalid\n",
      "get_similar_artists\n",
      "get_artist_terms\n",
      "get_artist_terms_freq\n",
      "get_artist_terms_weight\n",
      "get_analysis_sample_rate\n",
      "get_audio_md5\n",
      "get_danceability\n",
      "get_duration\n",
      "get_end_of_fade_in\n",
      "get_energy\n",
      "get_key\n",
      "get_key_confidence\n",
      "get_loudness\n",
      "get_mode\n",
      "get_mode_confidence\n",
      "get_start_of_fade_out\n",
      "get_tempo\n",
      "get_time_signature\n",
      "get_time_signature_confidence\n",
      "get_track_id\n",
      "get_segments_start\n",
      "get_segments_confidence\n",
      "get_segments_pitches\n",
      "get_segments_timbre\n",
      "get_segments_loudness_max\n",
      "get_segments_loudness_max_time\n",
      "get_segments_loudness_start\n",
      "get_sections_start\n",
      "get_sections_confidence\n",
      "get_beats_start\n",
      "get_beats_confidence\n",
      "get_bars_start\n",
      "get_bars_confidence\n",
      "get_tatums_start\n",
      "get_tatums_confidence\n",
      "get_artist_mbtags\n",
      "get_artist_mbtags_count\n",
      "get_year\n"
     ]
    }
   ],
   "source": [
    "# list all getters\n",
    "for x in filter(lambda x: x[:3] == 'get',hdf5_getters.__dict__.keys()):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "narrative-machine",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_additional_features(basedir,ext='.h5') :\n",
    "    track_ids = []\n",
    "    loudness = []\n",
    "    song_hotttnesss = []\n",
    "    tempo = []\n",
    "#     time_signature = []\n",
    "#     time_signature_confidence = []\n",
    "    for root, dirs, files in tqdm(os.walk(basedir)):\n",
    "        files = glob(os.path.join(root,'*'+ext))\n",
    "        for f in files:\n",
    "            h5 = hdf5_getters.open_h5_file_read(f)\n",
    "            track_ids.append(hdf5_getters.get_track_id(h5))\n",
    "            loudness.append(hdf5_getters.get_loudness(h5))\n",
    "            song_hotttnesss.append(hdf5_getters.get_song_hotttnesss(h5))\n",
    "            tempo.append(hdf5_getters.get_tempo(h5))\n",
    "#             time_signature.append(hdf5_getters.get_time_signature(h5))\n",
    "#             time_signature_confidence.append(hdf5_getters.get_time_signature_confidence(h5))\n",
    "            h5.close()\n",
    "    df_dict = {'track_id': track_ids,\n",
    "     'loudness': loudness,\n",
    "     'song_hotttnesss': song_hotttnesss,\n",
    "     'tempo': tempo}\n",
    "#      'time_signature': time_signature,\n",
    "#      'time_signature_confidence': time_signature_confidence}\n",
    "    return df_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finite-addition",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:46,  3.00s/it]"
     ]
    }
   ],
   "source": [
    "df_dict = get_additional_features(public_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "endless-civilian",
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_features = pd.DataFrame(df_dict)\n",
    "additional_features['track_id'] = additional_features['track_id'].apply(lambda x: x.split(\"\\'\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dated-launch",
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_features.to_csv(local_path+'additional_features_first.csv')\n",
    "# additional_features.to_csv(local_path + 'additional_features_second.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "meaningful-anthony",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "418035"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "additional_features['song_hotttnesss'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hollow-explanation",
   "metadata": {},
   "source": [
    "Use Dask for merging new features with features extracted from AddtionalFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intense-validity",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = dd.read_csv(local_path+'all_features.csv',header = 0).repartition(100)\n",
    "additional_features = dd.read_csv(local_path+'additional_features_first.csv',header = 0).repartition(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amino-flour",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features[features.columns[1:]].set_index('track_id')\n",
    "additional_features = additional_features[additional_features.columns[1:]].set_index('track_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contemporary-niagara",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = features.merge(additional_features,how = 'left', left_index = True, right_index= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaptive-money",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = all_features.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grateful-hayes",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features.reset_index().to_csv(local_path+'merged_all_features.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
